{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvj7HTvq9Dsi",
        "outputId": "e0f9d173-97d3-422b-8d21-eafce3f2d120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âš™ï¸ Using device: cpu\n",
            "ğŸ“¦ Total images found: 1475 across 10 classes: ['Fuchka', 'Jhalmuri', 'Kalavuna', 'Khichuri', 'Mishti', 'Pitha', 'Puri', 'Roshmalai', 'Shingara', 'Sugarcane Juice']\n",
            "ğŸŸ¢ Training images: 1180\n",
            "ğŸ“Š Training split distribution:\n",
            "   ğŸ“ Fuchka: 121 images\n",
            "   ğŸ“ Jhalmuri: 122 images\n",
            "   ğŸ“ Kalavuna: 131 images\n",
            "   ğŸ“ Khichuri: 115 images\n",
            "   ğŸ“ Mishti: 125 images\n",
            "   ğŸ“ Pitha: 122 images\n",
            "   ğŸ“ Puri: 119 images\n",
            "   ğŸ“ Roshmalai: 86 images\n",
            "   ğŸ“ Shingara: 122 images\n",
            "   ğŸ“ Sugarcane Juice: 117 images\n",
            "\n",
            "ğŸ”µ Validation images: 295\n",
            "ğŸ“Š Validation split distribution:\n",
            "   ğŸ“ Fuchka: 31 images\n",
            "   ğŸ“ Jhalmuri: 30 images\n",
            "   ğŸ“ Kalavuna: 21 images\n",
            "   ğŸ“ Khichuri: 37 images\n",
            "   ğŸ“ Mishti: 27 images\n",
            "   ğŸ“ Pitha: 30 images\n",
            "   ğŸ“ Puri: 33 images\n",
            "   ğŸ“ Roshmalai: 21 images\n",
            "   ğŸ“ Shingara: 30 images\n",
            "   ğŸ“ Sugarcane Juice: 35 images\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:59<00:00, 32.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc = 13.73%, Val Acc = 16.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:30<00:00, 31.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Acc = 30.68%, Val Acc = 51.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:31<00:00, 31.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Acc = 56.86%, Val Acc = 61.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:41<00:00, 31.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Acc = 62.12%, Val Acc = 60.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:57<00:00, 30.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Acc = 56.95%, Val Acc = 53.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:03<00:00, 30.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Acc = 54.83%, Val Acc = 57.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:51<00:00, 30.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Acc = 60.76%, Val Acc = 59.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:58<00:00, 30.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Acc = 60.93%, Val Acc = 61.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:08<00:00, 31.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Acc = 65.17%, Val Acc = 62.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:03<00:00, 30.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Acc = 68.98%, Val Acc = 62.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:07<00:00, 31.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Acc = 71.86%, Val Acc = 74.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:06<00:00, 31.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Acc = 73.56%, Val Acc = 75.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:15<00:00, 31.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Acc = 77.54%, Val Acc = 76.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:57<00:00, 32.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Acc = 79.24%, Val Acc = 79.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:28<00:00, 31.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Acc = 81.27%, Val Acc = 80.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:58<00:00, 30.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Acc = 82.12%, Val Acc = 83.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:41<00:00, 30.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Train Acc = 82.46%, Val Acc = 85.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:00<00:00, 30.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Acc = 84.49%, Val Acc = 84.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:24<00:00, 31.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Acc = 86.27%, Val Acc = 85.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:08<00:00, 31.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Acc = 85.51%, Val Acc = 87.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [19:04<00:00, 30.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Train Acc = 86.61%, Val Acc = 85.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:55<00:00, 30.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Train Acc = 88.47%, Val Acc = 87.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:39<00:00, 30.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Train Acc = 88.47%, Val Acc = 87.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:56<00:00, 30.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Train Acc = 87.71%, Val Acc = 86.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:58<00:00, 30.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Train Acc = 88.98%, Val Acc = 88.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:36<00:00, 30.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Train Acc = 89.07%, Val Acc = 87.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:39<00:00, 30.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: Train Acc = 90.42%, Val Acc = 89.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:09<00:00, 29.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: Train Acc = 90.00%, Val Acc = 89.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:23<00:00, 29.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: Train Acc = 90.93%, Val Acc = 89.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [18:34<00:00, 30.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Train Acc = 90.76%, Val Acc = 89.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 31/50 - Training:   0%|          | 0/37 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "# âœ… Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# âœ… Imports\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    confusion_matrix, roc_auc_score, roc_curve\n",
        ")\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# âœ… Count and print number of images per class\n",
        "def count_labels(dataset, class_names, split_name=\"\"):\n",
        "    labels = [sample[1] for sample in dataset]\n",
        "    label_counts = Counter(labels)\n",
        "    print(f\"\\U0001F4CA {split_name} split distribution:\")\n",
        "    for idx in range(len(class_names)):\n",
        "        print(f\"   \\U0001F4C1 {class_names[idx]}: {label_counts[idx]} images\")\n",
        "    print()\n",
        "\n",
        "# âœ… Load dataset\n",
        "def load_food_dataset(base_path, img_size=224, batch_size=32, split_ratio=0.8):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    full_dataset = datasets.ImageFolder(root=base_path, transform=transform)\n",
        "    class_names = full_dataset.classes\n",
        "    total_images = len(full_dataset)\n",
        "    print(f\"\\U0001F4E6 Total images found: {total_images} across {len(class_names)} classes: {class_names}\")\n",
        "\n",
        "    train_size = int(split_ratio * total_images)\n",
        "    val_size = total_images - train_size\n",
        "    train_set, val_set = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    print(f\"\\U0001F7E2 Training images: {len(train_set)}\")\n",
        "    count_labels(train_set, class_names, split_name=\"Training\")\n",
        "\n",
        "    print(f\"\\U0001F535 Validation images: {len(val_set)}\")\n",
        "    count_labels(val_set, class_names, split_name=\"Validation\")\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, class_names\n",
        "\n",
        "# âœ… Simple CNN\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 28 * 28, 256), nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# âœ… Combined VGG19 + SimpleCNN refinement model\n",
        "class VGG19_SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, feature_extract=True):\n",
        "        super().__init__()\n",
        "        vgg = models.vgg19_bn(pretrained=pretrained)  # âœ… FIXED\n",
        "        self.features = vgg.features\n",
        "        if feature_extract:\n",
        "            for p in self.features.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(256, 128, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 256), nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.refine(x)\n",
        "        return x\n",
        "\n",
        "# âœ… Get model\n",
        "def get_model(model_name, num_classes, device, pretrained=True, feature_extract=True):\n",
        "    model_name = model_name.lower()\n",
        "    if model_name == \"simple\":\n",
        "        model = SimpleCNN(num_classes)\n",
        "    elif model_name == \"vgg19\":\n",
        "        model = models.vgg19_bn(pretrained=pretrained)\n",
        "        if feature_extract:\n",
        "            for p in model.features.parameters():\n",
        "                p.requires_grad = False\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "    elif model_name in {\"combo\", \"vgg19+simple\"}:\n",
        "        model = VGG19_SimpleCNN(num_classes, pretrained, feature_extract)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model_name\")\n",
        "    return model.to(device)\n",
        "\n",
        "# âœ… Train model\n",
        "def evaluate_model(model, val_loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return 100. * correct / total\n",
        "\n",
        "def train_model(model, train_loader, val_loader, device, epochs=4, lr=0.001, save_path='model.pth'):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    train_acc_list, val_acc_list = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        correct, total, train_loss = 0, 0, 0.0\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = 100. * correct / total\n",
        "        val_acc = evaluate_model(model, val_loader, device)\n",
        "        train_acc_list.append(train_acc)\n",
        "        val_acc_list.append(val_acc)\n",
        "        print(f\"Epoch {epoch+1}: Train Acc = {train_acc:.2f}%, Val Acc = {val_acc:.2f}%\")\n",
        "\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"âœ… Model saved at: {save_path}\")\n",
        "\n",
        "    plt.plot(train_acc_list, label='Train Accuracy')\n",
        "    plt.plot(val_acc_list, label='Val Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Training & Validation Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# âœ… Evaluate\n",
        "def evaluate_model_detailed(model, val_loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    probs, roc_data_available = None, False\n",
        "    try:\n",
        "        probs = []\n",
        "        with torch.no_grad():\n",
        "            for images, _ in val_loader:\n",
        "                images = images.to(device)\n",
        "                outputs = model(images)\n",
        "                probs.append(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "        probs = np.vstack(probs)\n",
        "        from sklearn.preprocessing import label_binarize\n",
        "        labels_one_hot = label_binarize(all_labels, classes=list(range(probs.shape[1])))\n",
        "        auc = roc_auc_score(labels_one_hot, probs, average='weighted', multi_class='ovr')\n",
        "        roc_data_available = True\n",
        "    except:\n",
        "        auc = None\n",
        "\n",
        "    return accuracy, precision, recall, cm, auc, roc_data_available, all_labels, all_preds, probs\n",
        "\n",
        "# âœ… Predict\n",
        "def predict_image(model, image_path, class_names, device):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        _, predicted = output.max(1)\n",
        "        predicted_class = class_names[predicted.item()]\n",
        "    print(f\"ğŸ” Prediction for '{os.path.basename(image_path)}': {predicted_class}\")\n",
        "\n",
        "# âœ… Main\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"âš™ï¸ Using device: {device}\")\n",
        "\n",
        "    data_path = '/content/drive/MyDrive/Dataset/Dataset/Combined/Our dataset'\n",
        "    model_save_path = '/content/drive/MyDrive/Dataset/Dataset/Samifood_model_vgg_ourdataset.pth'\n",
        "\n",
        "    train_loader, val_loader, class_names = load_food_dataset(data_path)\n",
        "    model = get_model(\"combo\", len(class_names), device, pretrained=True, feature_extract=True)\n",
        "\n",
        "    train_model(model, train_loader, val_loader, device, epochs=50, lr=1e-5, save_path=model_save_path)\n",
        "\n",
        "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
        "    accuracy, precision, recall, cm, auc, roc_data_available, all_labels, all_preds, probs = evaluate_model_detailed(model, val_loader, device)\n",
        "    print(f\"\\nğŸ“Š Validation Metrics:\\nAccuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    if auc is not None:\n",
        "        print(f\"ROC AUC: {auc:.4f}\")\n",
        "        plt.figure(figsize=(8,6))\n",
        "        for i in range(len(class_names)):\n",
        "            fpr, tpr, _ = roc_curve(np.array(all_labels) == i, probs[:, i])\n",
        "            plt.plot(fpr, tpr, label=f\"Class {class_names[i]} (AUC = {roc_auc_score(np.array(all_labels) == i, probs[:, i]):.2f})\")\n",
        "        plt.plot([0,1],[0,1],'k--')\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.title(\"ROC Curve - Multiclass\")\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"ROC AUC curve not available.\")\n",
        "\n",
        "    test_image_path = f\"/content/drive/MyDrive/Dataset/Dataset/Combined/Our dataset/Sugarcane Juice/f52981ca1c92d937fd3fd6fc9eb26215.jpg\"\n",
        "    predict_image(model, test_image_path, class_names, device)\n",
        "\n",
        "# âœ… Run\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}