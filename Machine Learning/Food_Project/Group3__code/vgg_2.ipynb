{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDe8g_I5A4uN",
        "outputId": "ab5690a7-48fa-481b-d77a-5091f59cd566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚öôÔ∏è device: cpu\n",
            "üì¶ Found 1695 images across 13 classes.\n",
            "üìä Train split:\n",
            "         Chanachur: 36\n",
            "            Fuchka: 160\n",
            "          Jhalmuri: 181\n",
            "          Kalavuna: 29\n",
            "          Khichuri: 169\n",
            "     Mango pudding: 16\n",
            "            Mishti: 350\n",
            "             Pitha: 82\n",
            "             Pizza: 48\n",
            "              Puri: 152\n",
            "         Roshmalai: 44\n",
            "          Shingara: 50\n",
            "   Sugarcane Juice: 39\n",
            "\n",
            "üìä Val split:\n",
            "         Chanachur: 9\n",
            "            Fuchka: 47\n",
            "          Jhalmuri: 40\n",
            "          Kalavuna: 6\n",
            "          Khichuri: 34\n",
            "     Mango pudding: 2\n",
            "            Mishti: 101\n",
            "             Pitha: 10\n",
            "             Pizza: 11\n",
            "              Puri: 35\n",
            "         Roshmalai: 15\n",
            "          Shingara: 20\n",
            "   Sugarcane Juice: 9\n",
            "\n",
            "‚è± Data ready in 434.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/hub/checkpoints/vgg19_bn-c79401a0.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 548M/548M [00:06<00:00, 95.6MB/s]\n",
            "Epoch 1/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:15<00:00, 28.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 2.5669 | Train 4.42% | Val 3.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:08<00:00, 28.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 2.5207 | Train 28.54% | Val 40.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:11<00:00, 28.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 2.4251 | Train 31.56% | Val 29.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [19:59<00:00, 27.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 2.2723 | Train 26.18% | Val 29.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:19<00:00, 28.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 2.1172 | Train 32.89% | Val 40.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:14<00:00, 28.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.9703 | Train 37.68% | Val 41.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [19:51<00:00, 27.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.8326 | Train 41.00% | Val 50.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:21<00:00, 28.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.7098 | Train 52.80% | Val 62.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:18<00:00, 28.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.6011 | Train 60.25% | Val 64.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:00<00:00, 27.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.5122 | Train 62.54% | Val 69.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:01<00:00, 27.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.4290 | Train 66.00% | Val 70.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [19:54<00:00, 27.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.3453 | Train 66.30% | Val 70.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [19:53<00:00, 27.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.2695 | Train 67.99% | Val 71.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [19:52<00:00, 27.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.2226 | Train 68.14% | Val 71.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:04<00:00, 28.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.1574 | Train 69.47% | Val 71.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:15<00:00, 28.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.1083 | Train 69.84% | Val 71.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:21<00:00, 28.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.0640 | Train 69.99% | Val 72.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:20<00:00, 28.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 1.0224 | Train 71.17% | Val 71.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:12<00:00, 28.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 0.9939 | Train 70.21% | Val 72.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:00<00:00, 27.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 0.9754 | Train 69.99% | Val 72.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:07<00:00, 28.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 0.9286 | Train 71.68% | Val 73.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:05<00:00, 28.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 0.9065 | Train 71.98% | Val 73.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:05<00:00, 28.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 0.8798 | Train 73.45% | Val 73.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:08<00:00, 28.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 0.8623 | Train 74.19% | Val 74.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:02<00:00, 27.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 0.8221 | Train 74.85% | Val 75.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:05<00:00, 28.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 0.8077 | Train 74.71% | Val 75.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:14<00:00, 28.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 0.7893 | Train 76.03% | Val 76.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [20:03<00:00, 28.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Loss 0.7677 | Train 76.33% | Val 75.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 20/43 [09:35<10:57, 28.59s/it]"
          ]
        }
      ],
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë  Food‚ÄëImage Classifier ‚Äì VGG19‚ÄØ+‚ÄØSimpleCNN (multi‚Äëfolder)  ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "#  ‚úî Mounts Google¬†Drive\n",
        "#  ‚úî Loads images from *both* ‚ÄúOur dataset‚Äù & ‚ÄúExisting dataset‚Äù\n",
        "#  ‚úî One shared class‚Äëto‚Äëindex mapping\n",
        "#  ‚úî Skips unreadable / missing images\n",
        "#  ‚úî Trains combo model (VGG19 backbone ‚Üí SimpleCNN‚Äëstyle head)\n",
        "#  ‚úî Detailed metrics + ROC curves\n",
        "#  ‚úî Single‚Äëimage prediction helper\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "# ‚ñë‚ñë 1.  Mount Drive ‚ñë‚ñë\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ‚ñë‚ñë 2.  Imports ‚ñë‚ñë\n",
        "import os, time, numpy as np\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             confusion_matrix, roc_auc_score, roc_curve)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# ‚ñë‚ñë 3.  CombinedDataset ‚ñë‚ñë\n",
        "class CombinedDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Collect images from multiple root folders while keeping a shared label map.\n",
        "    Any class missing in one root is simply skipped for that folder.\n",
        "    \"\"\"\n",
        "    def __init__(self, roots, transform=None, exts=None):\n",
        "        self.roots = roots\n",
        "        self.transform = transform\n",
        "        self.exts = exts or {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}\n",
        "\n",
        "        # build global class list\n",
        "        all_classes = set()\n",
        "        for root in roots:\n",
        "            all_classes |= {d.name for d in os.scandir(root) if d.is_dir()}\n",
        "        self.classes = sorted(all_classes)\n",
        "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
        "\n",
        "        # gather samples\n",
        "        self.samples = []\n",
        "        for root in roots:\n",
        "            for cls in self.classes:\n",
        "                d = os.path.join(root, cls)\n",
        "                if not os.path.isdir(d):\n",
        "                    continue\n",
        "                for f in os.listdir(d):\n",
        "                    if os.path.splitext(f)[1].lower() in self.exts:\n",
        "                        self.samples.append((os.path.join(d, f),\n",
        "                                             self.class_to_idx[cls]))\n",
        "        print(f\"üì¶ Found {len(self.samples)} images across {len(self.classes)} classes.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGB\")\n",
        "        except (FileNotFoundError, UnidentifiedImageError):\n",
        "            # fall back to another sample\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# ‚ñë‚ñë 4.  Helpers ‚ñë‚ñë\n",
        "def count_labels(dataset, class_names, split_name):\n",
        "    cnt = Counter(y for _, y in dataset)\n",
        "    print(f\"üìä {split_name} split:\")\n",
        "    for i, cls in enumerate(class_names):\n",
        "        print(f\"   {cls:>15}: {cnt.get(i,0)}\")\n",
        "    print()\n",
        "\n",
        "def make_loaders(roots, img_size=224, batch=32, split=0.8):\n",
        "    tfm = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    full = CombinedDataset(roots, transform=tfm)\n",
        "    classes = full.classes\n",
        "\n",
        "    n_train = int(len(full) * split)\n",
        "    n_val = len(full) - n_train\n",
        "    train_set, val_set = random_split(full, [n_train, n_val])\n",
        "\n",
        "    count_labels(train_set, classes, \"Train\")\n",
        "    count_labels(val_set, classes, \"Val\")\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=batch, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_set,   batch_size=batch, shuffle=False, num_workers=2)\n",
        "    return train_loader, val_loader, classes\n",
        "\n",
        "# ‚ñë‚ñë 5.  Models ‚ñë‚ñë\n",
        "class SimpleCNNHead(nn.Module):\n",
        "    \"\"\"Refinement head that takes VGG19's 512‚Äëchannel feature map.\"\"\"\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                   # 7√ó7 ‚Üí 3√ó3\n",
        "            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 256), nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "    def forward(self, x): return self.refine(x)\n",
        "\n",
        "class VGG19_SimpleCNN(nn.Module):\n",
        "    \"\"\"Backbone = VGG19‚ÄëBN conv block¬†; head = custom SimpleCNNHead.\"\"\"\n",
        "    def __init__(self, num_classes, pretrained=True, feature_extract=True):\n",
        "        super().__init__()\n",
        "        vgg = models.vgg19_bn(weights=models.VGG19_BN_Weights.DEFAULT\n",
        "                              if pretrained else None)\n",
        "        self.features = vgg.features              # ‚üπ output 512√ó7√ó7\n",
        "        if feature_extract:\n",
        "            for p in self.features.parameters():\n",
        "                p.requires_grad = False\n",
        "        self.head = SimpleCNNHead(num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.head(x)\n",
        "\n",
        "def get_model(num_classes, device, pretrained=True, feature_extract=True):\n",
        "    model = VGG19_SimpleCNN(num_classes, pretrained, feature_extract)\n",
        "    return model.to(device)\n",
        "\n",
        "# ‚ñë‚ñë 6.  Train &¬†Eval ‚ñë‚ñë\n",
        "@torch.no_grad()\n",
        "def val_acc(model, loader, device):\n",
        "    model.eval()\n",
        "    hit = tot = 0\n",
        "    for x, y in loader:\n",
        "        out = model(x.to(device)).argmax(1)\n",
        "        hit += (out.cpu() == y).sum().item()\n",
        "        tot += y.size(0)\n",
        "    return 100 * hit / tot\n",
        "\n",
        "def train(model, train_loader, val_loader, device,\n",
        "          epochs=20, lr=1e-5, save_path='model.pth'):\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    tr_hist, vl_hist = [], []\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        hit = tot = loss_sum = 0\n",
        "        for x, y in tqdm(train_loader, desc=f'Epoch {ep}/{epochs}'):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = crit(out, y)\n",
        "            loss.backward(); opt.step()\n",
        "            loss_sum += loss.item() * x.size(0)\n",
        "            hit += (out.argmax(1) == y).sum().item()\n",
        "            tot += y.size(0)\n",
        "        tr_acc = 100 * hit / tot\n",
        "        vl_acc = val_acc(model, val_loader, device)\n",
        "        tr_hist.append(tr_acc); vl_hist.append(vl_acc)\n",
        "        print(f\"  Loss {loss_sum/tot:.4f} | Train {tr_acc:.2f}% | Val {vl_acc:.2f}%\")\n",
        "    torch.save(model.state_dict(), save_path); print(\"üíæ saved:\", save_path)\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(tr_hist, label='train'); plt.plot(vl_hist, label='val')\n",
        "    plt.xlabel('epoch'); plt.ylabel('accuracy (%)')\n",
        "    plt.title('Accuracy'); plt.grid(); plt.legend(); plt.show()\n",
        "\n",
        "@torch.no_grad()\n",
        "def detailed_report(model, loader, classes, device):\n",
        "    model.eval()\n",
        "    all_p, all_y, all_prob = [], [], []\n",
        "    for x, y in loader:\n",
        "        out = model(x.to(device))\n",
        "        all_p.append(out.argmax(1).cpu().numpy())\n",
        "        all_prob.append(torch.softmax(out,1).cpu().numpy())\n",
        "        all_y.append(y.numpy())\n",
        "    y = np.concatenate(all_y); p = np.concatenate(all_p); prob = np.vstack(all_prob)\n",
        "\n",
        "    acc  = accuracy_score(y, p)\n",
        "    prec = precision_score(y, p, average='weighted', zero_division=0)\n",
        "    rec  = recall_score(y, p, average='weighted', zero_division=0)\n",
        "    print(f\"\\nüìä Metrics\\n Accuracy : {acc:.4f}\\n Precision: {prec:.4f}\\n Recall   : {rec:.4f}\\n\")\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y, p))\n",
        "\n",
        "    try:\n",
        "        y_bin = label_binarize(y, classes=range(len(classes)))\n",
        "        auc = roc_auc_score(y_bin, prob, average='weighted', multi_class='ovr')\n",
        "        print(f\" ROC‚ÄëAUC  : {auc:.4f}\")\n",
        "\n",
        "        plt.figure(figsize=(7,6))\n",
        "        for i, cls in enumerate(classes):\n",
        "            fpr, tpr, _ = roc_curve((y == i).astype(int), prob[:, i])\n",
        "            plt.plot(fpr, tpr,\n",
        "                     label=f'{cls} (AUC {roc_auc_score((y==i), prob[:, i]):.2f})')\n",
        "        plt.plot([0,1],[0,1],'k--'); plt.legend()\n",
        "        plt.title('ROC curves'); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.grid(); plt.show()\n",
        "    except Exception as e:\n",
        "        print(\"AUC not available ‚ûú\", e)\n",
        "\n",
        "# ‚ñë‚ñë 7.  Prediction helper ‚ñë‚ñë\n",
        "def predict_one(model, img_path, classes, device):\n",
        "    tfm = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    pred = model(tfm(img).unsqueeze(0).to(device)).argmax(1).item()\n",
        "    print(f\"üîÆ {os.path.basename(img_path)} ‚ûú {classes[pred]}\")\n",
        "\n",
        "# ‚ñë‚ñë 8.  Main ‚ñë‚ñë\n",
        "def main():\n",
        "    # ‚ö†Ô∏è  Point to your two dataset roots\n",
        "    roots = [\n",
        "        '/content/drive/MyDrive/Dataset/Dataset/Our dataset',\n",
        "        '/content/drive/MyDrive/Dataset/Dataset/Existing dataset'\n",
        "    ]\n",
        "    save_path = '/content/drive/MyDrive/Dataset/Dataset/Samifood_model_vgg_combo.pth'\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"‚öôÔ∏è device:\", device)\n",
        "\n",
        "    # data\n",
        "    t0 = time.time()\n",
        "    train_loader, val_loader, classes = make_loaders(roots)\n",
        "    print(f\"‚è± Data ready in {time.time()-t0:.1f}s\")\n",
        "\n",
        "    # model\n",
        "    model = get_model(len(classes), device,\n",
        "                      pretrained=True, feature_extract=True)\n",
        "    train(model, train_loader, val_loader, device,\n",
        "          epochs=30, lr=1e-5, save_path=save_path)\n",
        "\n",
        "    # evaluation\n",
        "    model.load_state_dict(torch.load(save_path, map_location=device))\n",
        "    detailed_report(model, val_loader, classes, device)\n",
        "\n",
        "    # quick test ‚Äì change path if you like\n",
        "    test_img = f\"/content/drive/MyDrive/Dataset/Dataset/Our dataset/Mango pudding/IMG20250608133835.jpg\"\n",
        "    predict_one(model, test_img, classes, device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}